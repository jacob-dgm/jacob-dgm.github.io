<!DOCTYPE html>
<html lang="en">
<head>
	<title>A Human’s Guide to Machine Intelligence - Bookshelf - Jacob deGroot-Maggetti</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" type="text/css" href="/style.css">
</head>

<!-- Have you:
Updated the date in the footer?
Linked to this file within bookshelf/index.html ?
-->

<body class="page">
	<div class="header-cont">
		<div class="header">
			<h6 class="right">
				<a href="/bookshelf/">Bookshelf</a> – <a href="/">Jacob deGroot-Maggetti</a>
			</h6>
		</div>
	</div>
	
	<div class="content">
	
		<h2 class="title">
			A Human’s Guide to Machine Intelligence – Kartik Hosanagar
		</h2>
	
		<p><strong>Thoughts:</strong> I wrote up handwritten notes on this one back in 2019; now that I’m getting around to digitizing them in 2022, I remember very little about the book. Didn’t make a big impact on me.</p>
		<p>(The notes below are not a summary of the book, but rather raw notes - whatever I thought, at the time, might be worth remembering.)</p>
	
		<div class="hr"></div>
	
		<p>Hosanagar, Kartik. 2019. <em>A Human’s Guide to Machine Intelligence</em>. Viking.</p>
		
		<ul>
			<li>45: unanticipated consequences: proposed by Adam Smith; popularized by Robert Merton. 3 kinds:
				<ul>
					<li>unforeseen benefits</li>
					<li>perverse results - cause an opposite effect on the metric you’re trying to change</li>
					<li>unexpected drawbacks - cause a negative effect on a metric you’re not trying to change</li>
				</ul>
			</li>
			<li>74: Book mentioned: Chris Anderson’s <em>The Long Tail</em>. Suggests that automated recommendations can help people find relevant niche products/information</li>
			<li>79: content-based (as opposed to context-based) recommendation systems are better at surfacing relevant gems that may otherwise go undiscovered.</li>
			<li>89: book mentioned: Marvin Minsky &amp; Seymour Pappert (1969) <em>Perceptrons</em> - outlined limitation of neural networks</li>
			<li>102: to look up: Samuel Arbesman’s <em>Overcomplicated</em>.</li>
			<li>135: Music recommendation-algorithms leads to increased overlap in music consumption. Due to:
				<ol type="1">
					<li>Listeners listen more when exposed to the algorithm’s suggestions</li>
					<li>Algorithm helped people discover new interests</li>
				</ol>
				<ul>
					<li>conclusion: at least sometimes, algorithms can lead to less fragmentation; diminish echo chamber effects</li>
				</ul>
			</li>
			<li>140: algorithm behaviour can differ in different contexts. In one environment an algorithm might mitigate echo-chamber effects, while, in another, the same algorithm could exacerbate the problem.</li>
			<li>156: Humans much more readily lose faith in an algorithm that makes mistakes than in a human that makes the same mistakes</li>
			<li>176: humans tend to trust algorithms when they have some control over them, even if this control is minimal</li>
			<li>192: in human discourse, there is such thing as the “right amount” of transparency - more than secretive, less than TMI. Hosanagar suggests a similar principle should be followed in cultivating trust in algorithms.</li>
			<li>194: three categories of explanations in justifying a decision: how, why, trade-off. Each is most appropriate in certain situations:
				<ul>
					<li>How: to allay weakened confidence belief</li>
					<li>Why: to allay weakened benevolence belief (self-interest)</li>
					<li>Trade-off: to allay weakened integrity belief (fairness, honesty)</li>
				</ul>
			</li>
		</ul>
		
	
		<div class="dateline">
			<p>
				Posted: Nov 11, 2022. Last updated: Nov 11, 2022.
			</p>
		</div>
	</div>
	
	<div class="footer-cont">
		<div class="footer">
			<h6 class="left">
				<a href="/">Home</a> – <a href="/about">About</a> – <a href="/music" target="_blank">Music</a> – <a href="/blog">Blog</a> – <a href="/bookshelf">Bookshelf</a> – <a href="/etc">Etc.</a> – <a href="/contact">Contact</a>
			</h6>
		</div>
	</div>
	
</body>
</html>